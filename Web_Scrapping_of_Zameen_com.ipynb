{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "metadata": {
        "id": "49UrYR5o46Xy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "cdyct-axwQg5"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a time limit (e.g., 5 minutes)\n",
        "time_limit = timedelta(seconds=60)\n",
        "start_time = datetime.now()\n",
        "\n",
        "## Zammen.com is used for web scrapping task\n",
        "url_original = 'https://www.zameen.com/Homes/Faisalabad-16-{}.html'\n",
        "property_URL = []\n",
        "property_prices = []\n",
        "listing_title = []\n",
        "\n",
        "for pp in range(1,40):\n",
        "  ## get content from this HTML page\n",
        "  url = url_original.format(pp)\n",
        "  response = requests.get(url)\n",
        "\n",
        "  ## Check if request is successful\n",
        "  if response.status_code == 200:\n",
        "    print('Successfully fetched content')\n",
        "  else:\n",
        "    print('Try again')\n",
        "\n",
        "  soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "  ## Property Links\n",
        "\n",
        "  divs = soup.find_all('div', class_='f74e80f3')\n",
        "  for div in divs:\n",
        "    anchors = div.find_all('a')\n",
        "    for aa in anchors:\n",
        "      property_URL.append(aa['href'])\n",
        "\n",
        "  ## prices\n",
        "\n",
        "  prices = soup.find_all('span', class_='f343d9ce' ) #{'aria-label':\"Price\"}\n",
        "  for p in prices:\n",
        "    property_prices.append(p.text)\n",
        "\n",
        "\n",
        "  title_elements = soup.find_all('h2', {'aria-label': 'Title'})\n",
        "  for i in title_elements:\n",
        "    listing_title.append((i.text))\n",
        "\n",
        "## Dictionary to store all of them\n",
        "main_list = []\n",
        "for i in range(len(listing_title)):\n",
        "  property_dict = {}\n",
        "  property_dict['Title'] = listing_title[i]\n",
        "  property_dict['Price'] = property_prices[i]\n",
        "  property_dict['URL'] = property_URL[i]\n",
        "  main_list.append(property_dict)\n",
        "\n",
        "\n",
        "# Check if scraping time exceeds the time limit\n",
        "elapsed_time = datetime.now() - start_time\n",
        "if elapsed_time > time_limit:\n",
        "  print(\"Time limit reached. Exiting scraping process.\")\n",
        "else:\n",
        "  import json\n",
        "  # Save the JSON data to a file named 'property_dict.json'\n",
        "  with open('property_listings.json', 'w') as f:\n",
        "    json.dump(main_list,f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuoJUvBq6R4y",
        "outputId": "48205e9b-ce2f-4dd9-d0e7-a7e4d8e27cc0"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n",
            "Successfully fetched content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(main_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naaI9t3vylSY",
        "outputId": "1ec1d706-4fef-4e67-f6e1-50858956dadc"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "951"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    }
  ]
}